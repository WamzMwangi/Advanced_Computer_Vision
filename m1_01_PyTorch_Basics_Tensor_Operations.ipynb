{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VqhklyZ_zeFa"
   },
   "source": [
    "# PyTorch for Beginners\n",
    "\n",
    "In this notebook, we will try out the codes we used in the [PyTorch for Beginners](https://www.learnopencv.com/pytorch-for-beginners-basics/) blog.\n",
    "\n",
    "\n",
    " <img src='https://opencv.org/wp-content/uploads/2023/05/c3_w1_pytorch_basics_cover.jpg' width=700 align='center'><br/>\n",
    "\n",
    "Let's start off by installing PyTorch.\n",
    "\n",
    "\n",
    "\n",
    "## Table of Contents\n",
    "* [1. Converting Image to tensors](#1.-Converting-Image-to-tensors)\n",
    "* [2. Introduction to Tensors and its Operations](#2.-Introduction-to-Tensors-and-its-Operations)\n",
    "\n",
    "* [3. Conclusion](#5.-Conclusion)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TfSSU72-wLrw"
   },
   "source": [
    "# Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lu6Nap-AzvIk"
   },
   "outputs": [],
   "source": [
    "# Use this if you have conda installed\n",
    "# !conda install -c pytorch pytorch\n",
    "\n",
    "# Use this if you are on Google Colab\n",
    "# or don't have conda installed\n",
    "# !pip3 install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OTFNPvbNYSy1",
    "outputId": "f579d100-5195-4ba6-9e38-31754164f0eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Building wheel for torchviz (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
     ]
    }
   ],
   "source": [
    "# # Package to visualise computation graph\n",
    "!pip install -q torchviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-PfSnTVfcwMO"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "'''# Download some digit images from MNIST dataset\n",
    "!wget -q \"https://learnopencv.com/wp-content/uploads/2024/07/mnist_0.jpg\" -O \"mnist_0.jpg\"\n",
    "!wget -q \"https://learnopencv.com/wp-content/uploads/2024/07/mnist_1.jpg\" -O \"mnist_1.jpg\"'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qXlDsyiT0QkG"
   },
   "source": [
    "Let's verify that we have the latest PyTorch version (1.1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "XTu5IogH3Xgq"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4peb4GAdVnVI",
    "outputId": "6df9c375-93f9-4530-fe46-3376c8ff08d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version : 2.7.1+cpu\n"
     ]
    }
   ],
   "source": [
    "print(\"torch version : {}\".format(torch.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lgbl_exQeSBG"
   },
   "source": [
    "# 1. Converting Images to Batched tensors\n",
    "\n",
    "An image is made up of pixel arrays that represent the intensity of pixels in grayscale or the color values in RGB format. When working with deep learning models, it's often necessary to convert these images into tensors, which are the primary data structures used in PyTorch for handling and processing data.\n",
    "\n",
    "* **Tensors**: In PyTorch, tensors are multi-dimensional arrays similar to NumPy arrays, but with additional capabilities for GPU acceleration and automatic differentiation. Tensors are the fundamental building blocks for representing data and parameters in neural networks.\n",
    "* **Batches**: Batching is a technique where multiple data samples (images, in this case) are grouped together into a single tensor. This allows efficient processing of multiple samples simultaneously, to take advantage of the parallel processing capabilities of modern hardware.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z12KLdsrp8xR"
   },
   "source": [
    "In the following block, we will see an example of converting two MNIST images into a single batched tensor of shape `[2,3,28,28]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download the images from the internet, !wget will not work in the vscode env, so use a python method\n",
    "\n",
    "import requests\n",
    "url_1=\"https://learnopencv.com/wp-content/uploads/2024/07/mnist_0.jpg\"\n",
    "filename_1=\"mnist_0.jpg\"\n",
    "response_1=requests.get(url_1)\n",
    "with open(filename_1, \"wb\") as f:\n",
    "    f.write(response_1.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_2=\"https://learnopencv.com/wp-content/uploads/2024/07/mnist_1.jpg\"\n",
    "filename_2=\"mnist_1.jpg\"\n",
    "response_2=requests.get(url_2)\n",
    "with open(filename_2, \"wb\") as f:\n",
    "    f.write(response_2.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 411
    },
    "id": "kVI3AFLLbS3E",
    "outputId": "0a36a695-f6f2-498c-be4e-ad02d3332069"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "digit_0_array_og = cv2.imread(\"mnist_0.jpg\")\n",
    "digit_1_array_og = cv2.imread(\"mnist_1.jpg\")\n",
    "\n",
    "digit_0_array_gray = cv2.imread(\"mnist_0.jpg\",cv2.IMREAD_GRAYSCALE )\n",
    "digit_1_array_gray = cv2.imread(\"mnist_1.jpg\",cv2.IMREAD_GRAYSCALE )\n",
    "\n",
    "# Visualize the image\n",
    "\n",
    "fig, axs = plt.subplots(1,2, figsize=(10,5))\n",
    "\n",
    "\n",
    "axs[0].imshow(digit_0_array_og, cmap='gray',interpolation='none')\n",
    "axs[0].set_title(\"Digit 0 Image\")\n",
    "axs[0].axis('off')\n",
    "\n",
    "axs[1].imshow(digit_1_array_og, cmap=\"gray\", interpolation = 'none')\n",
    "axs[1].set_title(\"Digit 1 Image\")\n",
    "axs[1].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ttB6pUHUdIm4",
    "outputId": "248bd937-f89b-457d-90f6-5ad17298e2da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image array shape:  (28, 28, 3)\n",
      "Min pixel value:0 ; Max pixel value : 255\n"
     ]
    }
   ],
   "source": [
    "#Numpy array with three channels\n",
    "print(\"Image array shape: \",digit_0_array_og.shape)\n",
    "print(f\"Min pixel value:{np.min(digit_0_array_og)} ; Max pixel value : {np.max(digit_0_array_og)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "oUCmiJ7_nwtw",
    "outputId": "c8f35780-db2e-4b3d-aad2-190a63256eec"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "      .ndarray_repr .ndarray_raw_data {\n",
       "        display: none;\n",
       "      }\n",
       "      .ndarray_repr.show_array .ndarray_raw_data {\n",
       "        display: block;\n",
       "      }\n",
       "      .ndarray_repr.show_array .ndarray_image_preview {\n",
       "        display: none;\n",
       "      }\n",
       "      </style>\n",
       "      <div id=\"id-f90a2a6b-ccec-496c-8661-f4eb63bb94b5\" class=\"ndarray_repr\"><pre>ndarray (28, 28) <button style=\"padding: 0 2px;\">show data</button></pre><img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAB5ElEQVR4nMWSv2sUURSFv3fnvXnzdrM7cQOSZFHWWhIRywgRKxG0sbEQJGCRP8BGC7WwsQ+aXggsgpWInWJhUGsRURQSJIH8Yo3ZmezOzrXYjfgfeNvD+biccwDwhogGEUQQEKoYAPAeAEmwQGyRSKAKgEFiGwIIkUmRccTD8aFxDBIDCEAd8IEhC4DIgR2nUo9P3H2punxxGtKR5h1hDCxnX6luqm501y+AHT6SQgy1eKmj+fbbJ28Gxe+NOy4eOcFz7vWPMsuXThJP0rq9pSsjrIUKD7uarV4BAQ/nd9dmBeMAS33uo+r7GZOCwQo86rY9WISAvV8U71qAI7Jg3FX9Pm6IcCTwuMxmPUnARhFYJvJyyiK2b3oY8rAuFAUuA4RmbJwBgRJ30C+ms1QIJcBg4rLpGDAiivR7yYdPzU6vkR0meDPYOdVNyxIRC6Ih/mx+WnZjcgqtzNyo9Ac6qs0t781Tx2ISArht1eVhCKGKuadzGBxGgGZbsy/To4iEqYX8mifGAO7MM93XpSOpArWvmlIlxPiFvcN9fTo7FFOQmFub3ZXFydalBy8OMtXn9m/ZSYTMr5W5dlVVVXeu12ocO+ICNFa3eqqqv7R9unG0L8RhjUsIi+1Ortm3m5V/FvQf7g9SnKBxm+913QAAAABJRU5ErkJggg==\" class=\"ndarray_image_preview\" /><pre class=\"ndarray_raw_data\">array([[  0,   0,   0,   0,   7,   1,   0,   3,   0,  18,   0,   3,   0,\n",
       "          0,   3,   0,   0,   9,   0,   2,   0,  11,   0,   1,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   7,   7,   0,   0,   0,   0,   0,   2,   8,   0,   4,   0,\n",
       "          0,   0,   6,   4,   0,   2,   3,   2,   0,   0,  11,   0,   0,\n",
       "          0,   0],\n",
       "       [  1,   0,   2,   6,   4,   9,   9,   0,   0,   2,   0,   3,   1,\n",
       "         15,   0,   2,  16,   0,   2,   7,   0,   0,  22,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [ 12,   0,   0,   8,   1,   0,   0,   0,   2,   0,   0,   0,   0,\n",
       "         14,   0,   0,   0,   7,   9,   0,   7,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   3,   5,   0,   0,   4,  16,   0,  10,  14,   6,  29,\n",
       "        122, 182, 255, 255, 152,  66,  26,   0,   0,  15,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   7,   5,   0,   9,  12,   0,   0,   4,   0,  49, 184, 255,\n",
       "        255, 232, 255, 255, 231, 246, 227,  64,   0,   0,   4,   0,   0,\n",
       "          0,   0],\n",
       "       [  2,  15,   0,   0,   6,   0,   0,  13,   6, 148, 241, 255, 248,\n",
       "        236, 194, 151, 192, 253, 252, 244, 231, 121,   5,   6,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   7,   0,   0,   7,   0,  51, 191, 223, 254, 247, 248, 148,\n",
       "         30,   0,   6,  24,   0,  32, 116, 235, 255, 166,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   4,   0,   0,  10,   0, 132, 246, 255, 247, 199,  77,   0,\n",
       "          0,   2,   0,   0,   7,   0,   0,  60, 238, 226,  46,   2,   0,\n",
       "          1,   5],\n",
       "       [  0,   0,   4,   0,  14,  59, 203, 255, 255, 201,  45,   1,  15,\n",
       "          0,   0,   1,   0,   4,   2,   0,   0, 137, 246, 169,   7,   0,\n",
       "          0,   4],\n",
       "       [  2,   0,   9,   0,   4, 127, 252, 252, 198,  32,   0,   0,   0,\n",
       "          5,   0,   3,   4,   0,   0,   1,   5,  78, 255, 222,  16,   1,\n",
       "          0,   3],\n",
       "       [  5,   0,   8,   0,   0, 150, 254, 247,  46,   7,   0,   8,   9,\n",
       "          0,   4,   3,   3,   0,   0,   4,   0,  19, 248, 254,  25,   4,\n",
       "          0,   2],\n",
       "       [  0,   1,   2,   0,   1, 150, 246, 255,  17,   9,   0,   4,   0,\n",
       "          0,   9,   0,   0,   0,   0,   6,   0,  46, 254, 255,  30,   5,\n",
       "          0,   2],\n",
       "       [  0,   1,   0,   0,   6, 139, 241, 251,  43,   0,  15,   6,   0,\n",
       "          9,   7,   0,   0,   0,   0,   3,  19, 120, 255, 240,  31,   5,\n",
       "          0,   3],\n",
       "       [  2,   0,   0,   2,   1, 133, 249, 197,   0,  27,   0,   0,  18,\n",
       "          0,   0,   8,   0,   7,   1,   0,   0, 153, 245, 255,  29,   3,\n",
       "          0,   5],\n",
       "       [  6,   0,   0,   4,   0, 142, 255, 156,   1,   0,   4,   0,   0,\n",
       "          6,   0,   0,   0,   3,   0,  10,  45, 245, 255, 250,  26,   2,\n",
       "          0,   6],\n",
       "       [  0,   0,   0,   0,   5, 152, 239,  63,   0,  14,   0,   4,   0,\n",
       "          1,   8,   0,   9,   0,   0,   5, 236, 255, 255, 152,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   9,  11,   0,   1, 126, 255,  59,   0,   1,   0,   5,   0,\n",
       "          1,   2,   0,   0,   0,  27, 169, 255, 247, 217,  26,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   2,   0,  25,  97, 248,  83,   7,   0,   6,   0,   1,\n",
       "          0,   0,   0,   5,  47, 171, 255, 243, 255, 148,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  2,   0,  10,   0,   0,  13, 219, 255,  15,   0,  11,   0,   9,\n",
       "          6,   0,   7,  97, 239, 249, 243, 255, 163,  46,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [ 15,   0,   0,   2,   6,   0, 100, 232, 246, 166, 104,  24,  32,\n",
       "         72, 128, 180, 245, 247, 255, 255, 174,   4,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   8,   3,   0,   2,  63, 226, 254, 248, 255, 246, 255,\n",
       "        255, 255, 255, 255, 255, 237,  88,  13,  13,   0,  17,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   2,   0,   0,   0,   0,   0,  18, 199, 235, 250, 255, 255,\n",
       "        255, 255, 242, 255, 169,  43,  18,   0,   0,  11,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  2,   5,   0,   4,   1,   5,   8,   0,   9, 104, 169, 241, 248,\n",
       "        255, 247, 220,  95,  10,   7,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)</pre></div><script>\n",
       "      (() => {\n",
       "      const titles = ['show data', 'hide data'];\n",
       "      let index = 0\n",
       "      document.querySelector('#id-f90a2a6b-ccec-496c-8661-f4eb63bb94b5 button').onclick = (e) => {\n",
       "        document.querySelector('#id-f90a2a6b-ccec-496c-8661-f4eb63bb94b5').classList.toggle('show_array');\n",
       "        index = (++index) % 2;\n",
       "        document.querySelector('#id-f90a2a6b-ccec-496c-8661-f4eb63bb94b5 button').textContent = titles[index];\n",
       "        e.preventDefault();\n",
       "        e.stopPropagation();\n",
       "      }\n",
       "      })();\n",
       "    </script>"
      ],
      "text/plain": [
       "array([[  0,   0,   0,   0,   7,   1,   0,   3,   0,  18,   0,   3,   0,\n",
       "          0,   3,   0,   0,   9,   0,   2,   0,  11,   0,   1,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   7,   7,   0,   0,   0,   0,   0,   2,   8,   0,   4,   0,\n",
       "          0,   0,   6,   4,   0,   2,   3,   2,   0,   0,  11,   0,   0,\n",
       "          0,   0],\n",
       "       [  1,   0,   2,   6,   4,   9,   9,   0,   0,   2,   0,   3,   1,\n",
       "         15,   0,   2,  16,   0,   2,   7,   0,   0,  22,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [ 12,   0,   0,   8,   1,   0,   0,   0,   2,   0,   0,   0,   0,\n",
       "         14,   0,   0,   0,   7,   9,   0,   7,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   3,   5,   0,   0,   4,  16,   0,  10,  14,   6,  29,\n",
       "        122, 182, 255, 255, 152,  66,  26,   0,   0,  15,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   7,   5,   0,   9,  12,   0,   0,   4,   0,  49, 184, 255,\n",
       "        255, 232, 255, 255, 231, 246, 227,  64,   0,   0,   4,   0,   0,\n",
       "          0,   0],\n",
       "       [  2,  15,   0,   0,   6,   0,   0,  13,   6, 148, 241, 255, 248,\n",
       "        236, 194, 151, 192, 253, 252, 244, 231, 121,   5,   6,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   7,   0,   0,   7,   0,  51, 191, 223, 254, 247, 248, 148,\n",
       "         30,   0,   6,  24,   0,  32, 116, 235, 255, 166,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   4,   0,   0,  10,   0, 132, 246, 255, 247, 199,  77,   0,\n",
       "          0,   2,   0,   0,   7,   0,   0,  60, 238, 226,  46,   2,   0,\n",
       "          1,   5],\n",
       "       [  0,   0,   4,   0,  14,  59, 203, 255, 255, 201,  45,   1,  15,\n",
       "          0,   0,   1,   0,   4,   2,   0,   0, 137, 246, 169,   7,   0,\n",
       "          0,   4],\n",
       "       [  2,   0,   9,   0,   4, 127, 252, 252, 198,  32,   0,   0,   0,\n",
       "          5,   0,   3,   4,   0,   0,   1,   5,  78, 255, 222,  16,   1,\n",
       "          0,   3],\n",
       "       [  5,   0,   8,   0,   0, 150, 254, 247,  46,   7,   0,   8,   9,\n",
       "          0,   4,   3,   3,   0,   0,   4,   0,  19, 248, 254,  25,   4,\n",
       "          0,   2],\n",
       "       [  0,   1,   2,   0,   1, 150, 246, 255,  17,   9,   0,   4,   0,\n",
       "          0,   9,   0,   0,   0,   0,   6,   0,  46, 254, 255,  30,   5,\n",
       "          0,   2],\n",
       "       [  0,   1,   0,   0,   6, 139, 241, 251,  43,   0,  15,   6,   0,\n",
       "          9,   7,   0,   0,   0,   0,   3,  19, 120, 255, 240,  31,   5,\n",
       "          0,   3],\n",
       "       [  2,   0,   0,   2,   1, 133, 249, 197,   0,  27,   0,   0,  18,\n",
       "          0,   0,   8,   0,   7,   1,   0,   0, 153, 245, 255,  29,   3,\n",
       "          0,   5],\n",
       "       [  6,   0,   0,   4,   0, 142, 255, 156,   1,   0,   4,   0,   0,\n",
       "          6,   0,   0,   0,   3,   0,  10,  45, 245, 255, 250,  26,   2,\n",
       "          0,   6],\n",
       "       [  0,   0,   0,   0,   5, 152, 239,  63,   0,  14,   0,   4,   0,\n",
       "          1,   8,   0,   9,   0,   0,   5, 236, 255, 255, 152,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   9,  11,   0,   1, 126, 255,  59,   0,   1,   0,   5,   0,\n",
       "          1,   2,   0,   0,   0,  27, 169, 255, 247, 217,  26,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   2,   0,  25,  97, 248,  83,   7,   0,   6,   0,   1,\n",
       "          0,   0,   0,   5,  47, 171, 255, 243, 255, 148,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  2,   0,  10,   0,   0,  13, 219, 255,  15,   0,  11,   0,   9,\n",
       "          6,   0,   7,  97, 239, 249, 243, 255, 163,  46,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [ 15,   0,   0,   2,   6,   0, 100, 232, 246, 166, 104,  24,  32,\n",
       "         72, 128, 180, 245, 247, 255, 255, 174,   4,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   8,   3,   0,   2,  63, 226, 254, 248, 255, 246, 255,\n",
       "        255, 255, 255, 255, 255, 237,  88,  13,  13,   0,  17,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   2,   0,   0,   0,   0,   0,  18, 199, 235, 250, 255, 255,\n",
       "        255, 255, 242, 255, 169,  43,  18,   0,   0,  11,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  2,   5,   0,   4,   1,   5,   8,   0,   9, 104, 169, 241, 248,\n",
       "        255, 247, 220,  95,  10,   7,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We will have a look at 28x28 single channel image's pixel values\n",
    "digit_0_array_gray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hKA82xa7xDW9"
   },
   "source": [
    "### 1.1. Convert Numpy array to Torch tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 463
    },
    "id": "X3XeGklJdz36",
    "outputId": "f6c659d0-2675-4a7e-bee1-f79d68505953"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Normalised Digit 0 Tensor:  torch.Size([28, 28, 3])\n",
      "Normalised Min pixel value: 0.0 ; Normalised Max pixel value : 1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert the images to PyTorch tensors and normalize\n",
    "img_tensor_0 = torch.tensor(digit_0_array_og, dtype=torch.float32) / 255.0\n",
    "img_tensor_1 = torch.tensor(digit_1_array_og, dtype=torch.float32) / 255.0\n",
    "\n",
    "print(\"Shape of Normalised Digit 0 Tensor: \", img_tensor_0.shape)\n",
    "print(f\"Normalised Min pixel value: {torch.min(img_tensor_0)} ; Normalised Max pixel value : {torch.max(img_tensor_0)}\")\n",
    "\n",
    "plt.imshow(img_tensor_0,cmap=\"gray\")\n",
    "plt.title(\"Normalised Digit 0 Image\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K6C1MPtrgRYU"
   },
   "source": [
    "### 1.2. Creating Input Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oSLTIn0QgVC4",
    "outputId": "7deefcc9-6938-4c93-f364-06fa92089334"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Tensor Shape: torch.Size([2, 28, 28, 3])\n"
     ]
    }
   ],
   "source": [
    "batch_tensor = torch.stack([img_tensor_0, img_tensor_1])\n",
    "\n",
    "# In PyTorch the forward pass of input images to the model is expected to have a batch_size > 1\n",
    "print(\"Batch Tensor Shape:\", batch_tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fp_qlCZGhHSy"
   },
   "source": [
    "Additionally in PyTorch, image tensors typically follow the shape convention **[N\n",
    ",C ,H ,W]** unlike tensorflow which follows [N, H, W, C].\n",
    "\n",
    "Therefore, we need to bring the color channel to the second dimension. This can be achieved using either `torch.view()` or `torch.permute()`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xv3D1A0fhlIR",
    "outputId": "c7a97967-9260-4dc7-8e50-598ce9cc6b22"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Tensor Shape: torch.Size([2, 3, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "batch_input = batch_tensor.permute(0,3,1,2)\n",
    "print(\"Batch Tensor Shape:\", batch_input.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kp--FrJM0eoO"
   },
   "source": [
    "# 2. Introduction to Tensors and its Operations\n",
    "\n",
    "We have seen the importance of tensors, now will understand it from ground up.\n",
    "Tensor is simply a fancy name given to matrices. If you are familiar with NumPy arrays, understanding and using PyTorch Tensors will be very easy. A scalar value is represented by a 0-dimensional Tensor. Similarly, a column/row matrix is represented using a 1-D Tensor and so on. Some examples of Tensors with different dimensions are shown for you to visualize and understand.\n",
    "\n",
    "<img src=https://learnopencv.com/wp-content/uploads/2019/05/PyTorch-Tensors.jpg width = 400 height=350>\n",
    "\n",
    "## 2.1. Construct your first Tensor\n",
    "\n",
    "Let’s see how we can create a PyTorch Tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dwnMQMkHvbV_",
    "outputId": "9610b659-ed03-4673-98cf-00e56fa8b860"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n",
      "tensor([0., 0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "# Create a Tensor with just ones in a column\n",
    "a = torch.ones(5)\n",
    "# Print the tensor we created\n",
    "print(a)\n",
    "\n",
    "# Create a Tensor with just zeros in a column\n",
    "b = torch.zeros(5)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VZRb8bDz02PZ"
   },
   "source": [
    "We can similarly create Tensor with custom values as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PhuPnpNh0qMj",
    "outputId": "f1d2d373-0bed-4224-e9d7-6ea931ca4e1e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3., 4., 5.])\n"
     ]
    }
   ],
   "source": [
    "c = torch.tensor([1.0, 2.0, 3.0, 4.0, 5.0])\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rj4kSyaR08-5"
   },
   "source": [
    "In all the above cases, we have created vectors or Tensors of dimension 1. Now, let’s create some tensors of higher dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pwLThRRw05BJ",
    "outputId": "3ee1cbd0-932a-439f-8797-1fadf6436d75"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.]])\n",
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n",
      "tensor([[[1., 2.],\n",
      "         [3., 4.]],\n",
      "\n",
      "        [[5., 6.],\n",
      "         [7., 8.]]])\n"
     ]
    }
   ],
   "source": [
    "d = torch.zeros(3,2)\n",
    "print(d)\n",
    "\n",
    "e = torch.ones(3,2)\n",
    "print(e)\n",
    "\n",
    "f = torch.tensor([[1.0, 2.0],[3.0, 4.0]])\n",
    "print(f)\n",
    "\n",
    "# 3D Tensor\n",
    "g = torch.tensor([[[1., 2.], [3., 4.]], [[5., 6.], [7., 8.]]])\n",
    "print(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9cp28SfQ1Eb-"
   },
   "source": [
    "We can also find out the shape of a Tensor using **`.shape`** method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PrUhi7Me1CaE",
    "outputId": "8a29fb23-c1ef-440f-9b3f-f87536d87f20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2])\n",
      "torch.Size([3, 2])\n",
      "torch.Size([2, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "print(f.shape)\n",
    "\n",
    "print(e.shape)\n",
    "\n",
    "print(g.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vWHot39h1Z0X"
   },
   "source": [
    "## 2.2. Access an element in Tensor\n",
    "\n",
    "Now that we have created some tensors, let’s see how we can access an element in a Tensor. First let’s see how to do this for 1D Tensor aka vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1HP4gzrE1K66",
    "outputId": "138d1dcc-0a51-4aae-9cb0-94cfdcf293ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.)\n"
     ]
    }
   ],
   "source": [
    "# Get element at index 2\n",
    "print(c[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-gqFHFCV1k3H"
   },
   "source": [
    "What about 2D or 3D Tensor? Recall what we mentioned about **dimension of a tensor**.\n",
    "\n",
    "To access one particular element in a tensor, we will need to specify indices equal to the dimension of the tensor. That’s why for tensor **`c`** we only had to specify one index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IFR280DU1fJr",
    "outputId": "05f1ca07-61e7-424f-df6c-c0a8e9b5a857"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.)\n",
      "tensor(3.)\n",
      "tensor(5.)\n",
      "tensor(5.)\n"
     ]
    }
   ],
   "source": [
    "# All indices starting from 0\n",
    "\n",
    "# Get element at row 1, column 0\n",
    "print(f[1,0])\n",
    "\n",
    "# We can also use the following\n",
    "print(f[1][0])\n",
    "\n",
    "# Similarly for 3D Tensor\n",
    "print(g[1,0,0])\n",
    "print(g[1][0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jD0vwWDG1xr4"
   },
   "source": [
    "But what if you wanted to access one entire row in a 2D Tensor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XB_p7OUz1u9p",
    "outputId": "f01affd2-39ba-4f52-a7a1-61f606bc859d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n",
      "tensor([2., 3.])\n",
      "tensor([1., 2., 3., 4.])\n",
      "tensor([1., 2.])\n",
      "tensor([2., 4.])\n"
     ]
    }
   ],
   "source": [
    "# All elements\n",
    "print(f[:])\n",
    "\n",
    "# All elements from index 1 to 2 (inclusive)\n",
    "print(c[1:3])\n",
    "\n",
    "# All elements till index 4 (exclusive)\n",
    "print(c[:4])\n",
    "\n",
    "# First row\n",
    "print(f[0,:])\n",
    "\n",
    "# Second column\n",
    "print(f[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TxO2VoJv12Hh"
   },
   "source": [
    "## 2.3. Specify data type of elements\n",
    "\n",
    "Whenever we create a tensor, PyTorch decides the data type of the elements of the tensor such that the data type can cover all the elements of the tensor. We can override this by specifying the data type while creating the tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4AyDrCBS1z_x",
    "outputId": "87579129-9e6d-4bee-bd4d-4f8f0b05784a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.int64\n",
      "torch.float32\n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "torch.int64\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n"
     ]
    }
   ],
   "source": [
    "int_tensor = torch.tensor([[1,2,3],[4,5,6]])\n",
    "print(int_tensor.dtype)\n",
    "\n",
    "# What if we changed any one element to floating point number?\n",
    "int_tensor = torch.tensor([[1,2,3],[4.,5,6]])\n",
    "print(int_tensor.dtype)\n",
    "print(int_tensor)\n",
    "\n",
    "# This can be overridden as follows\n",
    "float_tensor = torch.tensor([[1, 2, 3],[4., 5, 6]])\n",
    "int_tensor = float_tensor.type(torch.int64)\n",
    "print(int_tensor.dtype)\n",
    "print(int_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nwxIIWEF2Ea8"
   },
   "source": [
    "## 2.4. Tensor to/from NumPy Array\n",
    "\n",
    "We have mentioned several times that PyTorch Tensors and NumPy arrays are pretty similar. This of course demands the question if it’s possible to convert one data structure into another. Let’s see how we can do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d7AC_jpn2Cd6",
    "outputId": "8f9d242b-7d56-40ea-d96b-fb74a196a937"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 2.]\n",
      " [3. 4.]]\n",
      "tensor([[8, 7, 6, 5],\n",
      "        [4, 3, 2, 1]])\n"
     ]
    }
   ],
   "source": [
    "# Tensor to Array\n",
    "f_numpy = f.numpy()\n",
    "print(f_numpy)\n",
    "\n",
    "# Array to Tensor\n",
    "h = np.array([[8,7,6,5],[4,3,2,1]])\n",
    "h_tensor = torch.from_numpy(h)\n",
    "print(h_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JBlMxo7j2NNH"
   },
   "source": [
    "## 2.5. Arithmetic Operations on Tensors\n",
    "\n",
    "Now it’s time for the next step. Let’s see how we can perform arithmetic operations on PyTorch tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CJGjZc212K74",
    "outputId": "92765dcf-f0f0-46a9-8836-01509d9fa067"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  4,  0],\n",
      "        [ 8,  0, 12]])\n",
      "tensor([[ 0,  4,  0],\n",
      "        [ 8,  0, 12]])\n",
      "tensor([[ 2,  0,  6],\n",
      "        [ 0, 10,  0]])\n",
      "tensor([[ 2,  0,  6],\n",
      "        [ 0, 10,  0]])\n",
      "tensor([[ 2,  4,  6],\n",
      "        [ 8, 10, 12]])\n",
      "tensor([[ -1,   4,  -9],\n",
      "        [ 16, -25,  36]])\n",
      "tensor([[22, 28],\n",
      "        [49, 64]])\n",
      "tensor([[0.5000, 1.0000, 1.5000],\n",
      "        [2.0000, 2.5000, 3.0000]])\n",
      "tensor([[-1.,  1., -1.],\n",
      "        [ 1., -1.,  1.]])\n"
     ]
    }
   ],
   "source": [
    "# Create tensor\n",
    "tensor1 = torch.tensor([[1,2,3],[4,5,6]])\n",
    "tensor2 = torch.tensor([[-1,2,-3],[4,-5,6]])\n",
    "\n",
    "# Addition\n",
    "print(tensor1+tensor2)\n",
    "# We can also use\n",
    "print(torch.add(tensor1,tensor2))\n",
    "\n",
    "# Subtraction\n",
    "print(tensor1-tensor2)\n",
    "# We can also use\n",
    "print(torch.sub(tensor1,tensor2))\n",
    "\n",
    "# Multiplication\n",
    "# Tensor with Scalar\n",
    "print(tensor1 * 2)\n",
    "\n",
    "# Tensor with another tensor\n",
    "# Elementwise Multiplication\n",
    "print(tensor1 * tensor2)\n",
    "\n",
    "# Matrix multiplication\n",
    "tensor3 = torch.tensor([[1,2],[3,4],[5,6]])\n",
    "print(torch.mm(tensor1,tensor3))\n",
    "\n",
    "# Division\n",
    "# Tensor with scalar\n",
    "print(tensor1/2)\n",
    "\n",
    "# Tensor with another tensor\n",
    "# Elementwise division\n",
    "print(tensor1/tensor2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n-wQZvbukBRL"
   },
   "source": [
    "## 2.6. Broadcasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LZ4u7hTLk1kf"
   },
   "source": [
    "   - `a` is a 1-dimensional tensor with shape \\([ 3 ]\\).\n",
    "   - `b` is a scalar tensor with shape \\([ ]\\).\n",
    "   - When adding `a` and `b`, PyTorch broadcasts `b` to match the shape of `a`, resulting in \\([ 1 + 4, 2 + 4, 3 + 4 ]\\).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RAPDFc7kkD7f",
    "outputId": "4a7863c2-75b2-4815-d23c-2b949c8b2a78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result of Broadcasting:\n",
      " tensor([5, 6, 7])\n"
     ]
    }
   ],
   "source": [
    "# Create two 1-dimensional tensors\n",
    "a = torch.tensor([1, 2, 3])\n",
    "b = torch.tensor([4])\n",
    "\n",
    "# adding a scalar to a vector\n",
    "result = a + b\n",
    "\n",
    "print(\"Result of Broadcasting:\\n\",result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e88PB3fnk6p1"
   },
   "source": [
    "[Broadcasting](https://pytorch.org/docs/stable/notes/broadcasting.html#broadcasting-semantics) allows PyTorch to perform element-wise operations on tensors of\n",
    "   - `a` is a 2-dimensional tensor with shape \\([1, 3]\\).\n",
    "   - `b` is a 2-dimensional tensor with shape \\([3, 1]\\).\n",
    "   - When adding `a` and `b`, PyTorch broadcasts both tensors to the common shape \\([3, 3]\\), resulting in:\n",
    "   \n",
    "     \\\n",
    "     \\begin{bmatrix}\n",
    "     1+4 & 2+4 & 3+4 \\\\\n",
    "     1+5 & 2+5 & 3+5 \\\\\n",
    "     1+6 & 2+6 & 3+6 \\\\\n",
    "     \\end{bmatrix}\n",
    "     \\.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YOoy7pRMk6Kx",
    "outputId": "1e835b05-fe03-46f7-bbb5-46e3c6165429"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:  torch.Size([3, 3])\n",
      "\n",
      "\n",
      "Result of Broadcasting:\n",
      " tensor([[5, 6, 7],\n",
      "        [6, 7, 8],\n",
      "        [7, 8, 9]])\n"
     ]
    }
   ],
   "source": [
    "# Create two tensors with shapes (1, 3) and (3, 1)\n",
    "a = torch.tensor([[1, 2, 3]])\n",
    "b = torch.tensor([[4], [5], [6]])\n",
    "\n",
    "# adding tensors of different shapes\n",
    "result = a + b\n",
    "print(\"Shape: \", result.shape)\n",
    "print(\"\\n\")\n",
    "print(\"Result of Broadcasting:\\n\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tkyA9q3_2mkE"
   },
   "source": [
    "## 2.7. CPU v/s GPU Tensor\n",
    "\n",
    "Let’s first see how to create a tensor for GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-zGZj6qR2XhM"
   },
   "outputs": [],
   "source": [
    "# Create a tensor for CPU\n",
    "# This will occupy CPU RAM\n",
    "tensor_cpu = torch.tensor([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]], device='cpu')\n",
    "\n",
    "# Create a tensor for GPU\n",
    "# This will occupy GPU RAM\n",
    "tensor_gpu = torch.tensor([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]], device='cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OgEU85m327Oc"
   },
   "source": [
    "Just like tensor creation, the operations performed for CPU and GPU tensors are also different and consume RAM corresponding to the device specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GCga1AY-2slu"
   },
   "outputs": [],
   "source": [
    "# This uses CPU RAM\n",
    "tensor_cpu = tensor_cpu * 5\n",
    "\n",
    "# This uses GPU RAM\n",
    "# Focus on GPU RAM Consumption\n",
    "tensor_gpu = tensor_gpu * 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jcJPGIwG2_Gk"
   },
   "source": [
    "We can move the GPU tensor to CPU and vice versa as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JjyOE2dG285K"
   },
   "outputs": [],
   "source": [
    "# Move GPU tensor to CPU\n",
    "tensor_gpu_cpu = tensor_gpu.to(device='cpu')\n",
    "\n",
    "# Move CPU tensor to GPU\n",
    "tensor_cpu_gpu = tensor_cpu.to(device='cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "znQT1rkq3BHL"
   },
   "source": [
    "# 3. Conclusion\n",
    "\n",
    "\n",
    "In this notebook, we started with constructing simple tensors and manipulating them.\n",
    "In the upcoming notebooks, we will go deeper into backpropagation and various computer vision tasks such as Classification, Segmentation, Object Detection, and Instance Segmentation. Each notebook will provide a detailed explanation and hands-on examples to help you serve as starter notebooks to master the essential tasks in computer vision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U-xo5g-msrfK"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "mlvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
