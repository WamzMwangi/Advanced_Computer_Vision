{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VqhklyZ_zeFa"
   },
   "source": [
    "# PyTorch for Beginners\n",
    "\n",
    "In this notebook, we will try out the codes we used in the [PyTorch for Beginners](https://www.learnopencv.com/pytorch-for-beginners-basics/) blog.\n",
    "\n",
    "\n",
    " <img src='https://opencv.org/wp-content/uploads/2023/05/c3_w1_pytorch_basics_cover.jpg' width=700 align='center'><br/>\n",
    "\n",
    "Let's start off by installing PyTorch.\n",
    "\n",
    "\n",
    "\n",
    "## Table of Contents\n",
    "* [1. Converting Image to tensors](#1.-Converting-Image-to-tensors)\n",
    "* [2. Introduction to Tensors and its Operations](#2.-Introduction-to-Tensors-and-its-Operations)\n",
    "\n",
    "* [3. Conclusion](#5.-Conclusion)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TfSSU72-wLrw"
   },
   "source": [
    "# Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lu6Nap-AzvIk"
   },
   "outputs": [],
   "source": [
    "# Use this if you have conda installed\n",
    "# !conda install -c pytorch pytorch\n",
    "\n",
    "# Use this if you are on Google Colab\n",
    "# or don't have conda installed\n",
    "# !pip3 install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OTFNPvbNYSy1",
    "outputId": "f579d100-5195-4ba6-9e38-31754164f0eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Building wheel for torchviz (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
     ]
    }
   ],
   "source": [
    "# # Package to visualise computation graph\n",
    "!pip install -q torchviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-PfSnTVfcwMO"
   },
   "outputs": [],
   "source": [
    "# Download some digit images from MNIST dataset\n",
    "!wget -q \"https://learnopencv.com/wp-content/uploads/2024/07/mnist_0.jpg\" -O \"mnist_0.jpg\"\n",
    "!wget -q \"https://learnopencv.com/wp-content/uploads/2024/07/mnist_1.jpg\" -O \"mnist_1.jpg\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qXlDsyiT0QkG"
   },
   "source": [
    "Let's verify that we have the latest PyTorch version (1.1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "XTu5IogH3Xgq"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4peb4GAdVnVI",
    "outputId": "6df9c375-93f9-4530-fe46-3376c8ff08d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version : 2.7.1+cpu\n"
     ]
    }
   ],
   "source": [
    "print(\"torch version : {}\".format(torch.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lgbl_exQeSBG"
   },
   "source": [
    "# 1. Converting Images to Batched tensors\n",
    "\n",
    "An image is made up of pixel arrays that represent the intensity of pixels in grayscale or the color values in RGB format. When working with deep learning models, it's often necessary to convert these images into tensors, which are the primary data structures used in PyTorch for handling and processing data.\n",
    "\n",
    "* **Tensors**: In PyTorch, tensors are multi-dimensional arrays similar to NumPy arrays, but with additional capabilities for GPU acceleration and automatic differentiation. Tensors are the fundamental building blocks for representing data and parameters in neural networks.\n",
    "* **Batches**: Batching is a technique where multiple data samples (images, in this case) are grouped together into a single tensor. This allows efficient processing of multiple samples simultaneously, to take advantage of the parallel processing capabilities of modern hardware.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z12KLdsrp8xR"
   },
   "source": [
    "In the following block, we will see an example of converting two MNIST images into a single batched tensor of shape `[2,3,28,28]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 411
    },
    "id": "kVI3AFLLbS3E",
    "outputId": "0a36a695-f6f2-498c-be4e-ad02d3332069"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "digit_0_array_og = cv2.imread(\"mnist_0.jpg\")\n",
    "digit_1_array_og = cv2.imread(\"mnist_1.jpg\")\n",
    "\n",
    "digit_0_array_gray = cv2.imread(\"mnist_0.jpg\",cv2.IMREAD_GRAYSCALE )\n",
    "digit_1_array_gray = cv2.imread(\"mnist_1.jpg\",cv2.IMREAD_GRAYSCALE )\n",
    "\n",
    "# Visualize the image\n",
    "\n",
    "fig, axs = plt.subplots(1,2, figsize=(10,5))\n",
    "\n",
    "\n",
    "axs[0].imshow(digit_0_array_og, cmap='gray',interpolation='none')\n",
    "axs[0].set_title(\"Digit 0 Image\")\n",
    "axs[0].axis('off')\n",
    "\n",
    "axs[1].imshow(digit_1_array_og, cmap=\"gray\", interpolation = 'none')\n",
    "axs[1].set_title(\"Digit 1 Image\")\n",
    "axs[1].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ttB6pUHUdIm4",
    "outputId": "248bd937-f89b-457d-90f6-5ad17298e2da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image array shape:  (28, 28, 3)\n",
      "Min pixel value:0 ; Max pixel value : 255\n"
     ]
    }
   ],
   "source": [
    "#Numpy array with three channels\n",
    "print(\"Image array shape: \",digit_0_array_og.shape)\n",
    "print(f\"Min pixel value:{np.min(digit_0_array_og)} ; Max pixel value : {np.max(digit_0_array_og)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "oUCmiJ7_nwtw",
    "outputId": "c8f35780-db2e-4b3d-aad2-190a63256eec"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "      .ndarray_repr .ndarray_raw_data {\n",
       "        display: none;\n",
       "      }\n",
       "      .ndarray_repr.show_array .ndarray_raw_data {\n",
       "        display: block;\n",
       "      }\n",
       "      .ndarray_repr.show_array .ndarray_image_preview {\n",
       "        display: none;\n",
       "      }\n",
       "      </style>\n",
       "      <div id=\"id-f90a2a6b-ccec-496c-8661-f4eb63bb94b5\" class=\"ndarray_repr\"><pre>ndarray (28, 28) <button style=\"padding: 0 2px;\">show data</button></pre><img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAB5ElEQVR4nMWSv2sUURSFv3fnvXnzdrM7cQOSZFHWWhIRywgRKxG0sbEQJGCRP8BGC7WwsQ+aXggsgpWInWJhUGsRURQSJIH8Yo3ZmezOzrXYjfgfeNvD+biccwDwhogGEUQQEKoYAPAeAEmwQGyRSKAKgEFiGwIIkUmRccTD8aFxDBIDCEAd8IEhC4DIgR2nUo9P3H2punxxGtKR5h1hDCxnX6luqm501y+AHT6SQgy1eKmj+fbbJ28Gxe+NOy4eOcFz7vWPMsuXThJP0rq9pSsjrIUKD7uarV4BAQ/nd9dmBeMAS33uo+r7GZOCwQo86rY9WISAvV8U71qAI7Jg3FX9Pm6IcCTwuMxmPUnARhFYJvJyyiK2b3oY8rAuFAUuA4RmbJwBgRJ30C+ms1QIJcBg4rLpGDAiivR7yYdPzU6vkR0meDPYOdVNyxIRC6Ih/mx+WnZjcgqtzNyo9Ac6qs0t781Tx2ISArht1eVhCKGKuadzGBxGgGZbsy/To4iEqYX8mifGAO7MM93XpSOpArWvmlIlxPiFvcN9fTo7FFOQmFub3ZXFydalBy8OMtXn9m/ZSYTMr5W5dlVVVXeu12ocO+ICNFa3eqqqv7R9unG0L8RhjUsIi+1Ortm3m5V/FvQf7g9SnKBxm+913QAAAABJRU5ErkJggg==\" class=\"ndarray_image_preview\" /><pre class=\"ndarray_raw_data\">array([[  0,   0,   0,   0,   7,   1,   0,   3,   0,  18,   0,   3,   0,\n",
       "          0,   3,   0,   0,   9,   0,   2,   0,  11,   0,   1,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   7,   7,   0,   0,   0,   0,   0,   2,   8,   0,   4,   0,\n",
       "          0,   0,   6,   4,   0,   2,   3,   2,   0,   0,  11,   0,   0,\n",
       "          0,   0],\n",
       "       [  1,   0,   2,   6,   4,   9,   9,   0,   0,   2,   0,   3,   1,\n",
       "         15,   0,   2,  16,   0,   2,   7,   0,   0,  22,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [ 12,   0,   0,   8,   1,   0,   0,   0,   2,   0,   0,   0,   0,\n",
       "         14,   0,   0,   0,   7,   9,   0,   7,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   3,   5,   0,   0,   4,  16,   0,  10,  14,   6,  29,\n",
       "        122, 182, 255, 255, 152,  66,  26,   0,   0,  15,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   7,   5,   0,   9,  12,   0,   0,   4,   0,  49, 184, 255,\n",
       "        255, 232, 255, 255, 231, 246, 227,  64,   0,   0,   4,   0,   0,\n",
       "          0,   0],\n",
       "       [  2,  15,   0,   0,   6,   0,   0,  13,   6, 148, 241, 255, 248,\n",
       "        236, 194, 151, 192, 253, 252, 244, 231, 121,   5,   6,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   7,   0,   0,   7,   0,  51, 191, 223, 254, 247, 248, 148,\n",
       "         30,   0,   6,  24,   0,  32, 116, 235, 255, 166,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   4,   0,   0,  10,   0, 132, 246, 255, 247, 199,  77,   0,\n",
       "          0,   2,   0,   0,   7,   0,   0,  60, 238, 226,  46,   2,   0,\n",
       "          1,   5],\n",
       "       [  0,   0,   4,   0,  14,  59, 203, 255, 255, 201,  45,   1,  15,\n",
       "          0,   0,   1,   0,   4,   2,   0,   0, 137, 246, 169,   7,   0,\n",
       "          0,   4],\n",
       "       [  2,   0,   9,   0,   4, 127, 252, 252, 198,  32,   0,   0,   0,\n",
       "          5,   0,   3,   4,   0,   0,   1,   5,  78, 255, 222,  16,   1,\n",
       "          0,   3],\n",
       "       [  5,   0,   8,   0,   0, 150, 254, 247,  46,   7,   0,   8,   9,\n",
       "          0,   4,   3,   3,   0,   0,   4,   0,  19, 248, 254,  25,   4,\n",
       "          0,   2],\n",
       "       [  0,   1,   2,   0,   1, 150, 246, 255,  17,   9,   0,   4,   0,\n",
       "          0,   9,   0,   0,   0,   0,   6,   0,  46, 254, 255,  30,   5,\n",
       "          0,   2],\n",
       "       [  0,   1,   0,   0,   6, 139, 241, 251,  43,   0,  15,   6,   0,\n",
       "          9,   7,   0,   0,   0,   0,   3,  19, 120, 255, 240,  31,   5,\n",
       "          0,   3],\n",
       "       [  2,   0,   0,   2,   1, 133, 249, 197,   0,  27,   0,   0,  18,\n",
       "          0,   0,   8,   0,   7,   1,   0,   0, 153, 245, 255,  29,   3,\n",
       "          0,   5],\n",
       "       [  6,   0,   0,   4,   0, 142, 255, 156,   1,   0,   4,   0,   0,\n",
       "          6,   0,   0,   0,   3,   0,  10,  45, 245, 255, 250,  26,   2,\n",
       "          0,   6],\n",
       "       [  0,   0,   0,   0,   5, 152, 239,  63,   0,  14,   0,   4,   0,\n",
       "          1,   8,   0,   9,   0,   0,   5, 236, 255, 255, 152,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   9,  11,   0,   1, 126, 255,  59,   0,   1,   0,   5,   0,\n",
       "          1,   2,   0,   0,   0,  27, 169, 255, 247, 217,  26,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   2,   0,  25,  97, 248,  83,   7,   0,   6,   0,   1,\n",
       "          0,   0,   0,   5,  47, 171, 255, 243, 255, 148,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  2,   0,  10,   0,   0,  13, 219, 255,  15,   0,  11,   0,   9,\n",
       "          6,   0,   7,  97, 239, 249, 243, 255, 163,  46,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [ 15,   0,   0,   2,   6,   0, 100, 232, 246, 166, 104,  24,  32,\n",
       "         72, 128, 180, 245, 247, 255, 255, 174,   4,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   8,   3,   0,   2,  63, 226, 254, 248, 255, 246, 255,\n",
       "        255, 255, 255, 255, 255, 237,  88,  13,  13,   0,  17,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   2,   0,   0,   0,   0,   0,  18, 199, 235, 250, 255, 255,\n",
       "        255, 255, 242, 255, 169,  43,  18,   0,   0,  11,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  2,   5,   0,   4,   1,   5,   8,   0,   9, 104, 169, 241, 248,\n",
       "        255, 247, 220,  95,  10,   7,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)</pre></div><script>\n",
       "      (() => {\n",
       "      const titles = ['show data', 'hide data'];\n",
       "      let index = 0\n",
       "      document.querySelector('#id-f90a2a6b-ccec-496c-8661-f4eb63bb94b5 button').onclick = (e) => {\n",
       "        document.querySelector('#id-f90a2a6b-ccec-496c-8661-f4eb63bb94b5').classList.toggle('show_array');\n",
       "        index = (++index) % 2;\n",
       "        document.querySelector('#id-f90a2a6b-ccec-496c-8661-f4eb63bb94b5 button').textContent = titles[index];\n",
       "        e.preventDefault();\n",
       "        e.stopPropagation();\n",
       "      }\n",
       "      })();\n",
       "    </script>"
      ],
      "text/plain": [
       "array([[  0,   0,   0,   0,   7,   1,   0,   3,   0,  18,   0,   3,   0,\n",
       "          0,   3,   0,   0,   9,   0,   2,   0,  11,   0,   1,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   7,   7,   0,   0,   0,   0,   0,   2,   8,   0,   4,   0,\n",
       "          0,   0,   6,   4,   0,   2,   3,   2,   0,   0,  11,   0,   0,\n",
       "          0,   0],\n",
       "       [  1,   0,   2,   6,   4,   9,   9,   0,   0,   2,   0,   3,   1,\n",
       "         15,   0,   2,  16,   0,   2,   7,   0,   0,  22,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [ 12,   0,   0,   8,   1,   0,   0,   0,   2,   0,   0,   0,   0,\n",
       "         14,   0,   0,   0,   7,   9,   0,   7,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   3,   5,   0,   0,   4,  16,   0,  10,  14,   6,  29,\n",
       "        122, 182, 255, 255, 152,  66,  26,   0,   0,  15,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   7,   5,   0,   9,  12,   0,   0,   4,   0,  49, 184, 255,\n",
       "        255, 232, 255, 255, 231, 246, 227,  64,   0,   0,   4,   0,   0,\n",
       "          0,   0],\n",
       "       [  2,  15,   0,   0,   6,   0,   0,  13,   6, 148, 241, 255, 248,\n",
       "        236, 194, 151, 192, 253, 252, 244, 231, 121,   5,   6,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   7,   0,   0,   7,   0,  51, 191, 223, 254, 247, 248, 148,\n",
       "         30,   0,   6,  24,   0,  32, 116, 235, 255, 166,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   4,   0,   0,  10,   0, 132, 246, 255, 247, 199,  77,   0,\n",
       "          0,   2,   0,   0,   7,   0,   0,  60, 238, 226,  46,   2,   0,\n",
       "          1,   5],\n",
       "       [  0,   0,   4,   0,  14,  59, 203, 255, 255, 201,  45,   1,  15,\n",
       "          0,   0,   1,   0,   4,   2,   0,   0, 137, 246, 169,   7,   0,\n",
       "          0,   4],\n",
       "       [  2,   0,   9,   0,   4, 127, 252, 252, 198,  32,   0,   0,   0,\n",
       "          5,   0,   3,   4,   0,   0,   1,   5,  78, 255, 222,  16,   1,\n",
       "          0,   3],\n",
       "       [  5,   0,   8,   0,   0, 150, 254, 247,  46,   7,   0,   8,   9,\n",
       "          0,   4,   3,   3,   0,   0,   4,   0,  19, 248, 254,  25,   4,\n",
       "          0,   2],\n",
       "       [  0,   1,   2,   0,   1, 150, 246, 255,  17,   9,   0,   4,   0,\n",
       "          0,   9,   0,   0,   0,   0,   6,   0,  46, 254, 255,  30,   5,\n",
       "          0,   2],\n",
       "       [  0,   1,   0,   0,   6, 139, 241, 251,  43,   0,  15,   6,   0,\n",
       "          9,   7,   0,   0,   0,   0,   3,  19, 120, 255, 240,  31,   5,\n",
       "          0,   3],\n",
       "       [  2,   0,   0,   2,   1, 133, 249, 197,   0,  27,   0,   0,  18,\n",
       "          0,   0,   8,   0,   7,   1,   0,   0, 153, 245, 255,  29,   3,\n",
       "          0,   5],\n",
       "       [  6,   0,   0,   4,   0, 142, 255, 156,   1,   0,   4,   0,   0,\n",
       "          6,   0,   0,   0,   3,   0,  10,  45, 245, 255, 250,  26,   2,\n",
       "          0,   6],\n",
       "       [  0,   0,   0,   0,   5, 152, 239,  63,   0,  14,   0,   4,   0,\n",
       "          1,   8,   0,   9,   0,   0,   5, 236, 255, 255, 152,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   9,  11,   0,   1, 126, 255,  59,   0,   1,   0,   5,   0,\n",
       "          1,   2,   0,   0,   0,  27, 169, 255, 247, 217,  26,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   2,   0,  25,  97, 248,  83,   7,   0,   6,   0,   1,\n",
       "          0,   0,   0,   5,  47, 171, 255, 243, 255, 148,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  2,   0,  10,   0,   0,  13, 219, 255,  15,   0,  11,   0,   9,\n",
       "          6,   0,   7,  97, 239, 249, 243, 255, 163,  46,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [ 15,   0,   0,   2,   6,   0, 100, 232, 246, 166, 104,  24,  32,\n",
       "         72, 128, 180, 245, 247, 255, 255, 174,   4,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   8,   3,   0,   2,  63, 226, 254, 248, 255, 246, 255,\n",
       "        255, 255, 255, 255, 255, 237,  88,  13,  13,   0,  17,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   2,   0,   0,   0,   0,   0,  18, 199, 235, 250, 255, 255,\n",
       "        255, 255, 242, 255, 169,  43,  18,   0,   0,  11,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  2,   5,   0,   4,   1,   5,   8,   0,   9, 104, 169, 241, 248,\n",
       "        255, 247, 220,  95,  10,   7,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We will have a look at 28x28 single channel image's pixel values\n",
    "digit_0_array_gray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hKA82xa7xDW9"
   },
   "source": [
    "### 1.1. Convert Numpy array to Torch tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 463
    },
    "id": "X3XeGklJdz36",
    "outputId": "f6c659d0-2675-4a7e-bee1-f79d68505953"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Normalised Digit 0 Tensor:  torch.Size([28, 28, 3])\n",
      "Normalised Min pixel value: 0.0 ; Normalised Max pixel value : 1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert the images to PyTorch tensors and normalize\n",
    "img_tensor_0 = torch.tensor(digit_0_array_og, dtype=torch.float32) / 255.0\n",
    "img_tensor_1 = torch.tensor(digit_1_array_og, dtype=torch.float32) / 255.0\n",
    "\n",
    "print(\"Shape of Normalised Digit 0 Tensor: \", img_tensor_0.shape)\n",
    "print(f\"Normalised Min pixel value: {torch.min(img_tensor_0)} ; Normalised Max pixel value : {torch.max(img_tensor_0)}\")\n",
    "\n",
    "plt.imshow(img_tensor_0,cmap=\"gray\")\n",
    "plt.title(\"Normalised Digit 0 Image\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K6C1MPtrgRYU"
   },
   "source": [
    "### 1.2. Creating Input Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oSLTIn0QgVC4",
    "outputId": "7deefcc9-6938-4c93-f364-06fa92089334"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Tensor Shape: torch.Size([2, 28, 28, 3])\n"
     ]
    }
   ],
   "source": [
    "batch_tensor = torch.stack([img_tensor_0, img_tensor_1])\n",
    "\n",
    "# In PyTorch the forward pass of input images to the model is expected to have a batch_size > 1\n",
    "print(\"Batch Tensor Shape:\", batch_tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fp_qlCZGhHSy"
   },
   "source": [
    "Additionally in PyTorch, image tensors typically follow the shape convention **[N\n",
    ",C ,H ,W]** unlike tensorflow which follows [N, H, W, C].\n",
    "\n",
    "Therefore, we need to bring the color channel to the second dimension. This can be achieved using either `torch.view()` or `torch.permute()`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xv3D1A0fhlIR",
    "outputId": "c7a97967-9260-4dc7-8e50-598ce9cc6b22"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Tensor Shape: torch.Size([2, 3, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "batch_input = batch_tensor.permute(0,3,1,2)\n",
    "print(\"Batch Tensor Shape:\", batch_input.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kp--FrJM0eoO"
   },
   "source": [
    "# 2. Introduction to Tensors and its Operations\n",
    "\n",
    "We have seen the importance of tensors, now will understand it from ground up.\n",
    "Tensor is simply a fancy name given to matrices. If you are familiar with NumPy arrays, understanding and using PyTorch Tensors will be very easy. A scalar value is represented by a 0-dimensional Tensor. Similarly, a column/row matrix is represented using a 1-D Tensor and so on. Some examples of Tensors with different dimensions are shown for you to visualize and understand.\n",
    "\n",
    "<img src=https://learnopencv.com/wp-content/uploads/2019/05/PyTorch-Tensors.jpg width = 400 height=350>\n",
    "\n",
    "## 2.1. Construct your first Tensor\n",
    "\n",
    "Let’s see how we can create a PyTorch Tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dwnMQMkHvbV_",
    "outputId": "9610b659-ed03-4673-98cf-00e56fa8b860"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n",
      "tensor([0., 0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "# Create a Tensor with just ones in a column\n",
    "a = torch.ones(5)\n",
    "# Print the tensor we created\n",
    "print(a)\n",
    "\n",
    "# Create a Tensor with just zeros in a column\n",
    "b = torch.zeros(5)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VZRb8bDz02PZ"
   },
   "source": [
    "We can similarly create Tensor with custom values as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PhuPnpNh0qMj",
    "outputId": "f1d2d373-0bed-4224-e9d7-6ea931ca4e1e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3., 4., 5.])\n"
     ]
    }
   ],
   "source": [
    "c = torch.tensor([1.0, 2.0, 3.0, 4.0, 5.0])\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rj4kSyaR08-5"
   },
   "source": [
    "In all the above cases, we have created vectors or Tensors of dimension 1. Now, let’s create some tensors of higher dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pwLThRRw05BJ",
    "outputId": "3ee1cbd0-932a-439f-8797-1fadf6436d75"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.]])\n",
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n",
      "tensor([[[1., 2.],\n",
      "         [3., 4.]],\n",
      "\n",
      "        [[5., 6.],\n",
      "         [7., 8.]]])\n"
     ]
    }
   ],
   "source": [
    "d = torch.zeros(3,2)\n",
    "print(d)\n",
    "\n",
    "e = torch.ones(3,2)\n",
    "print(e)\n",
    "\n",
    "f = torch.tensor([[1.0, 2.0],[3.0, 4.0]])\n",
    "print(f)\n",
    "\n",
    "# 3D Tensor\n",
    "g = torch.tensor([[[1., 2.], [3., 4.]], [[5., 6.], [7., 8.]]])\n",
    "print(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9cp28SfQ1Eb-"
   },
   "source": [
    "We can also find out the shape of a Tensor using **`.shape`** method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PrUhi7Me1CaE",
    "outputId": "8a29fb23-c1ef-440f-9b3f-f87536d87f20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2])\n",
      "torch.Size([3, 2])\n",
      "torch.Size([2, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "print(f.shape)\n",
    "\n",
    "print(e.shape)\n",
    "\n",
    "print(g.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vWHot39h1Z0X"
   },
   "source": [
    "## 2.2. Access an element in Tensor\n",
    "\n",
    "Now that we have created some tensors, let’s see how we can access an element in a Tensor. First let’s see how to do this for 1D Tensor aka vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1HP4gzrE1K66",
    "outputId": "138d1dcc-0a51-4aae-9cb0-94cfdcf293ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.)\n"
     ]
    }
   ],
   "source": [
    "# Get element at index 2\n",
    "print(c[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-gqFHFCV1k3H"
   },
   "source": [
    "What about 2D or 3D Tensor? Recall what we mentioned about **dimension of a tensor**.\n",
    "\n",
    "To access one particular element in a tensor, we will need to specify indices equal to the dimension of the tensor. That’s why for tensor **`c`** we only had to specify one index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IFR280DU1fJr",
    "outputId": "05f1ca07-61e7-424f-df6c-c0a8e9b5a857"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.)\n",
      "tensor(3.)\n",
      "tensor(5.)\n",
      "tensor(5.)\n"
     ]
    }
   ],
   "source": [
    "# All indices starting from 0\n",
    "\n",
    "# Get element at row 1, column 0\n",
    "print(f[1,0])\n",
    "\n",
    "# We can also use the following\n",
    "print(f[1][0])\n",
    "\n",
    "# Similarly for 3D Tensor\n",
    "print(g[1,0,0])\n",
    "print(g[1][0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jD0vwWDG1xr4"
   },
   "source": [
    "But what if you wanted to access one entire row in a 2D Tensor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XB_p7OUz1u9p",
    "outputId": "f01affd2-39ba-4f52-a7a1-61f606bc859d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n",
      "tensor([2., 3.])\n",
      "tensor([1., 2., 3., 4.])\n",
      "tensor([1., 2.])\n",
      "tensor([2., 4.])\n"
     ]
    }
   ],
   "source": [
    "# All elements\n",
    "print(f[:])\n",
    "\n",
    "# All elements from index 1 to 2 (inclusive)\n",
    "print(c[1:3])\n",
    "\n",
    "# All elements till index 4 (exclusive)\n",
    "print(c[:4])\n",
    "\n",
    "# First row\n",
    "print(f[0,:])\n",
    "\n",
    "# Second column\n",
    "print(f[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TxO2VoJv12Hh"
   },
   "source": [
    "## 2.3. Specify data type of elements\n",
    "\n",
    "Whenever we create a tensor, PyTorch decides the data type of the elements of the tensor such that the data type can cover all the elements of the tensor. We can override this by specifying the data type while creating the tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4AyDrCBS1z_x",
    "outputId": "87579129-9e6d-4bee-bd4d-4f8f0b05784a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.int64\n",
      "torch.float32\n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "torch.int64\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n"
     ]
    }
   ],
   "source": [
    "int_tensor = torch.tensor([[1,2,3],[4,5,6]])\n",
    "print(int_tensor.dtype)\n",
    "\n",
    "# What if we changed any one element to floating point number?\n",
    "int_tensor = torch.tensor([[1,2,3],[4.,5,6]])\n",
    "print(int_tensor.dtype)\n",
    "print(int_tensor)\n",
    "\n",
    "# This can be overridden as follows\n",
    "float_tensor = torch.tensor([[1, 2, 3],[4., 5, 6]])\n",
    "int_tensor = float_tensor.type(torch.int64)\n",
    "print(int_tensor.dtype)\n",
    "print(int_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nwxIIWEF2Ea8"
   },
   "source": [
    "## 2.4. Tensor to/from NumPy Array\n",
    "\n",
    "We have mentioned several times that PyTorch Tensors and NumPy arrays are pretty similar. This of course demands the question if it’s possible to convert one data structure into another. Let’s see how we can do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d7AC_jpn2Cd6",
    "outputId": "8f9d242b-7d56-40ea-d96b-fb74a196a937"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 2.]\n",
      " [3. 4.]]\n",
      "tensor([[8, 7, 6, 5],\n",
      "        [4, 3, 2, 1]])\n"
     ]
    }
   ],
   "source": [
    "# Tensor to Array\n",
    "f_numpy = f.numpy()\n",
    "print(f_numpy)\n",
    "\n",
    "# Array to Tensor\n",
    "h = np.array([[8,7,6,5],[4,3,2,1]])\n",
    "h_tensor = torch.from_numpy(h)\n",
    "print(h_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JBlMxo7j2NNH"
   },
   "source": [
    "## 2.5. Arithmetic Operations on Tensors\n",
    "\n",
    "Now it’s time for the next step. Let’s see how we can perform arithmetic operations on PyTorch tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CJGjZc212K74",
    "outputId": "92765dcf-f0f0-46a9-8836-01509d9fa067"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  4,  0],\n",
      "        [ 8,  0, 12]])\n",
      "tensor([[ 0,  4,  0],\n",
      "        [ 8,  0, 12]])\n",
      "tensor([[ 2,  0,  6],\n",
      "        [ 0, 10,  0]])\n",
      "tensor([[ 2,  0,  6],\n",
      "        [ 0, 10,  0]])\n",
      "tensor([[ 2,  4,  6],\n",
      "        [ 8, 10, 12]])\n",
      "tensor([[ -1,   4,  -9],\n",
      "        [ 16, -25,  36]])\n",
      "tensor([[22, 28],\n",
      "        [49, 64]])\n",
      "tensor([[0.5000, 1.0000, 1.5000],\n",
      "        [2.0000, 2.5000, 3.0000]])\n",
      "tensor([[-1.,  1., -1.],\n",
      "        [ 1., -1.,  1.]])\n"
     ]
    }
   ],
   "source": [
    "# Create tensor\n",
    "tensor1 = torch.tensor([[1,2,3],[4,5,6]])\n",
    "tensor2 = torch.tensor([[-1,2,-3],[4,-5,6]])\n",
    "\n",
    "# Addition\n",
    "print(tensor1+tensor2)\n",
    "# We can also use\n",
    "print(torch.add(tensor1,tensor2))\n",
    "\n",
    "# Subtraction\n",
    "print(tensor1-tensor2)\n",
    "# We can also use\n",
    "print(torch.sub(tensor1,tensor2))\n",
    "\n",
    "# Multiplication\n",
    "# Tensor with Scalar\n",
    "print(tensor1 * 2)\n",
    "\n",
    "# Tensor with another tensor\n",
    "# Elementwise Multiplication\n",
    "print(tensor1 * tensor2)\n",
    "\n",
    "# Matrix multiplication\n",
    "tensor3 = torch.tensor([[1,2],[3,4],[5,6]])\n",
    "print(torch.mm(tensor1,tensor3))\n",
    "\n",
    "# Division\n",
    "# Tensor with scalar\n",
    "print(tensor1/2)\n",
    "\n",
    "# Tensor with another tensor\n",
    "# Elementwise division\n",
    "print(tensor1/tensor2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n-wQZvbukBRL"
   },
   "source": [
    "## 2.6. Broadcasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LZ4u7hTLk1kf"
   },
   "source": [
    "   - `a` is a 1-dimensional tensor with shape \\([ 3 ]\\).\n",
    "   - `b` is a scalar tensor with shape \\([ ]\\).\n",
    "   - When adding `a` and `b`, PyTorch broadcasts `b` to match the shape of `a`, resulting in \\([ 1 + 4, 2 + 4, 3 + 4 ]\\).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RAPDFc7kkD7f",
    "outputId": "4a7863c2-75b2-4815-d23c-2b949c8b2a78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result of Broadcasting:\n",
      " tensor([5, 6, 7])\n"
     ]
    }
   ],
   "source": [
    "# Create two 1-dimensional tensors\n",
    "a = torch.tensor([1, 2, 3])\n",
    "b = torch.tensor([4])\n",
    "\n",
    "# adding a scalar to a vector\n",
    "result = a + b\n",
    "\n",
    "print(\"Result of Broadcasting:\\n\",result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e88PB3fnk6p1"
   },
   "source": [
    "[Broadcasting](https://pytorch.org/docs/stable/notes/broadcasting.html#broadcasting-semantics) allows PyTorch to perform element-wise operations on tensors of\n",
    "   - `a` is a 2-dimensional tensor with shape \\([1, 3]\\).\n",
    "   - `b` is a 2-dimensional tensor with shape \\([3, 1]\\).\n",
    "   - When adding `a` and `b`, PyTorch broadcasts both tensors to the common shape \\([3, 3]\\), resulting in:\n",
    "   \n",
    "     \\\n",
    "     \\begin{bmatrix}\n",
    "     1+4 & 2+4 & 3+4 \\\\\n",
    "     1+5 & 2+5 & 3+5 \\\\\n",
    "     1+6 & 2+6 & 3+6 \\\\\n",
    "     \\end{bmatrix}\n",
    "     \\.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YOoy7pRMk6Kx",
    "outputId": "1e835b05-fe03-46f7-bbb5-46e3c6165429"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:  torch.Size([3, 3])\n",
      "\n",
      "\n",
      "Result of Broadcasting:\n",
      " tensor([[5, 6, 7],\n",
      "        [6, 7, 8],\n",
      "        [7, 8, 9]])\n"
     ]
    }
   ],
   "source": [
    "# Create two tensors with shapes (1, 3) and (3, 1)\n",
    "a = torch.tensor([[1, 2, 3]])\n",
    "b = torch.tensor([[4], [5], [6]])\n",
    "\n",
    "# adding tensors of different shapes\n",
    "result = a + b\n",
    "print(\"Shape: \", result.shape)\n",
    "print(\"\\n\")\n",
    "print(\"Result of Broadcasting:\\n\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tkyA9q3_2mkE"
   },
   "source": [
    "## 2.7. CPU v/s GPU Tensor\n",
    "\n",
    "Let’s first see how to create a tensor for GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-zGZj6qR2XhM"
   },
   "outputs": [],
   "source": [
    "# Create a tensor for CPU\n",
    "# This will occupy CPU RAM\n",
    "tensor_cpu = torch.tensor([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]], device='cpu')\n",
    "\n",
    "# Create a tensor for GPU\n",
    "# This will occupy GPU RAM\n",
    "tensor_gpu = torch.tensor([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]], device='cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OgEU85m327Oc"
   },
   "source": [
    "Just like tensor creation, the operations performed for CPU and GPU tensors are also different and consume RAM corresponding to the device specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GCga1AY-2slu"
   },
   "outputs": [],
   "source": [
    "# This uses CPU RAM\n",
    "tensor_cpu = tensor_cpu * 5\n",
    "\n",
    "# This uses GPU RAM\n",
    "# Focus on GPU RAM Consumption\n",
    "tensor_gpu = tensor_gpu * 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jcJPGIwG2_Gk"
   },
   "source": [
    "We can move the GPU tensor to CPU and vice versa as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JjyOE2dG285K"
   },
   "outputs": [],
   "source": [
    "# Move GPU tensor to CPU\n",
    "tensor_gpu_cpu = tensor_gpu.to(device='cpu')\n",
    "\n",
    "# Move CPU tensor to GPU\n",
    "tensor_cpu_gpu = tensor_cpu.to(device='cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "znQT1rkq3BHL"
   },
   "source": [
    "# 3. Conclusion\n",
    "\n",
    "\n",
    "In this notebook, we started with constructing simple tensors and manipulating them.\n",
    "In the upcoming notebooks, we will go deeper into backpropagation and various computer vision tasks such as Classification, Segmentation, Object Detection, and Instance Segmentation. Each notebook will provide a detailed explanation and hands-on examples to help you serve as starter notebooks to master the essential tasks in computer vision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U-xo5g-msrfK"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "mlvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
